{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Libraries**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Data loading and preprocessing**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split):\n",
    "    path = \"../data/embeddings/generalEmbc/\" + split + \"/\"\n",
    "\n",
    "    ade_dat = np.load(path+\"adenomaEmbeddings.npy\")\n",
    "    ade_lab = np.load(path+\"adenomaLabels.npy\")\n",
    "    ade_vid = np.load(path+\"adenomaVideos.npy\") \n",
    "\n",
    "    hyp_dat = np.load(path+\"hiperplasticEmbeddings.npy\")\n",
    "    hyp_lab = np.load(path+\"hiperplasticLabels.npy\")\n",
    "    hyp_vid = np.load(path+\"hiperplasticVideos.npy\")\n",
    "    \n",
    "    ser_dat = np.load(path+\"serratedEmbeddings.npy\")\n",
    "    ser_lab = np.load(path+\"serratedLabels.npy\")\n",
    "    ser_vid = np.load(path+\"serratedVideos.npy\")\n",
    "\n",
    "    print(\"==== \"+ split + \" data info ====\")\n",
    "    print(\"ade dim: {}, amount of labels: {}, videos: {}\".format(ade_dat.shape, ade_lab.shape, ade_vid.shape))\n",
    "    print(\"hyp dim: {}, amount of labels: {}, videos: {}\".format(hyp_dat.shape, hyp_lab.shape, hyp_vid.shape))\n",
    "    print(\"ser dim: {}, amount of labels: {}, videos: {}\".format(ser_dat.shape, ser_lab.shape, ser_vid.shape))\n",
    "    \n",
    "    features = np.concatenate((ade_dat, hyp_dat, ser_dat), axis=0)\n",
    "    labels = np.concatenate((ade_lab, hyp_lab, ser_lab), axis=0)\n",
    "    videos = np.concatenate((ade_vid, hyp_vid, ser_vid), axis=0)\n",
    "    \n",
    "    df = pd.DataFrame({'features': list(features), 'label': labels, 'video': videos}, columns=['features', 'label', 'video'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split):\n",
    "    #path = \"../Embeddings/vggDiscriminator/\" + split + \"/\"\n",
    "    path = \"../../../unconditional/cycleGan-polyps/data/embeddings/adeVsHyp/embcBaseline/\" + split + '/'\n",
    "\n",
    "    ade_dat = np.load(path+\"adenomaEmbeddings.npy\")\n",
    "    ade_lab = np.load(path+\"adenomaLabels.npy\")\n",
    "    ade_vid = np.load(path+\"adenomaVideos.npy\") \n",
    "\n",
    "    hyp_dat = np.load(path+\"hiperplasticEmbeddings.npy\")\n",
    "    hyp_lab = np.load(path+\"hiperplasticLabels.npy\")\n",
    "    hyp_vid = np.load(path+\"hiperplasticVideos.npy\")\n",
    "    \n",
    "    print(\"==== \"+ split + \" data info ====\")\n",
    "    print(\"ade dim: {}, amount of labels: {}, videos: {}\".format(ade_dat.shape, ade_lab.shape, ade_vid.shape))\n",
    "    print(\"hyp dim: {}, amount of labels: {}, videos: {}\".format(hyp_dat.shape, hyp_lab.shape, hyp_vid.shape))\n",
    "    \n",
    "    features = np.concatenate((ade_dat, hyp_dat), axis=0)\n",
    "    labels = np.concatenate((ade_lab, hyp_lab), axis=0)\n",
    "    videos = np.concatenate((ade_vid, hyp_vid), axis=0)\n",
    "    \n",
    "    df = pd.DataFrame({'features': list(features), 'label': labels, 'video': videos}, columns=['features', 'label', 'video'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(split='train')\n",
    "train_df['info'] = train_df['label'] + '_' + train_df['video']\n",
    "print(\"train_df info:\")\n",
    "print(train_df.groupby(['label']).count())\n",
    "\n",
    "test_df = load_data(split='test')\n",
    "test_df['info'] = test_df['label'] + '_' + test_df['video']\n",
    "print(\"test_df info:\")\n",
    "print(test_df.groupby(['label']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    features = []\n",
    "    for i in range(len(df)):\n",
    "        tmp_features = df.loc[i]['features']\n",
    "        features.append(tmp_features)\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = get_features(train_df)\n",
    "print(\"train features shape: {}, min and max values: {} {}\".format(train_features.shape, train_features.min(),\n",
    "                                                                   train_features.max()))\n",
    "\n",
    "test_features = get_features(test_df)\n",
    "print(\"test features shape: {}, min and max values: {} {}\".format(test_features.shape, test_features.min(),\n",
    "                                                                   test_features.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3, random_state=69)\n",
    "pca.fit(train_features)\n",
    "pca_result = pca.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pca-one'] = pca_result[:,0]\n",
    "train_df['pca-two'] = pca_result[:,1] \n",
    "train_df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_result = pca.transform(test_features)\n",
    "test_df['pca-one'] = pca_result[:,0]\n",
    "test_df['pca-two'] = pca_result[:,1] \n",
    "test_df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tsne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2, init = 'pca')\n",
    "P1_tsne = tsne.fit_transform(train_features)\n",
    "P1_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x'] = l1\n",
    "train_df['y'] = l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_tsne = tsne.fit_transform(test_features)\n",
    "P1_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = P1_tsne[:,0]\n",
    "l2 = P1_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['x'] = l1\n",
    "test_df['y'] = l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Classifying**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_features, train_df['label'].values\n",
    "x_test, y_test = test_features, test_df['label'].values\n",
    "\n",
    "print(\"====Train info:====\")\n",
    "print(\"data shape:{}, labels: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"====Test info:====\")\n",
    "print(\"data shape:{}, labels: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.fit_transform(y_test)\n",
    "print(\"train labels:\")\n",
    "print(y_train_enc)\n",
    "print(\"test labels:\")\n",
    "print(y_test_enc)\n",
    "n_class = len(set(y_train_enc))\n",
    "print(\"number of classes: \", n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confussion_matrix(y_true, y_pred):\n",
    "    target_names = ['adenoma', 'hiperplastic']\n",
    "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation='horizontal', values_format='.2f')\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = '../../../unconditional/cycleGan-polyps/models_emb_classification/adeVsHyp/embcBaseline/'\n",
    "max_auc = -9999\n",
    "#for KNN\n",
    "for i in range(5, 40, 15):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "    print(\"===== for k =====\", i)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train_enc)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    pred_prob = knn.predict_proba(x_test)\n",
    "    acc = metrics.accuracy_score(y_test_enc, y_pred)\n",
    "    for j in range(n_class):   \n",
    "        fpr[j], tpr[j], thresh[j] = roc_curve(y_test_enc, pred_prob[:,j], pos_label=j)\n",
    "    ade_auc, hyp_auc = auc(fpr[0], tpr[0]), auc(fpr[1], tpr[1])\n",
    "    gen_auc = roc_auc_score(y_test_enc, np.argmax(pred_prob, axis=1))    \n",
    "    precision, recall, fscore, support = score(y_test_enc, y_pred, average='macro')\n",
    "    \n",
    "    filename = to_save + \"KNN\" + str(i) + '.pkl'\n",
    "    joblib.dump(knn, filename) \n",
    "    if gen_auc>max_auc:\n",
    "        max_auc = gen_auc\n",
    "        k_val = i\n",
    "        y_pred2 = y_pred\n",
    "        gen_auc2 = gen_auc\n",
    "        \n",
    "    print(\"METRICS:\")\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Fscore: \", fscore)\n",
    "    print(\"Gen AUC: \", gen_auc)\n",
    "    print(\"ade auc: \", ade_auc)\n",
    "    print(\"hyp auc: \", hyp_auc)\n",
    "    \n",
    "print(\"for KNN, the best model was the k value: \", k_val, \"with general auc: \", max_auc)\n",
    "print(\"confussion matrix:\")\n",
    "get_confussion_matrix(y_test_enc, y_pred2)\n",
    "\n",
    "#for random forest\n",
    "max_auc = -9999\n",
    "for i in range(10, 40, 10):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "    print(\"===== for \", i, \" trees =====\")\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=14)\n",
    "    rfc.fit(x_train, y_train_enc)\n",
    "    y_pred = rfc.predict(x_test)\n",
    "    pred_prob = rfc.predict_proba(x_test)\n",
    "    acc = metrics.accuracy_score(y_test_enc, y_pred)\n",
    "    for j in range(n_class):   \n",
    "        fpr[j], tpr[j], thresh[j] = roc_curve(y_test_enc, pred_prob[:,j], pos_label=j)\n",
    "    ade_auc, hyp_auc = auc(fpr[0], tpr[0]), auc(fpr[1], tpr[1])\n",
    "    gen_auc = roc_auc_score(y_test_enc, np.argmax(pred_prob, axis=1))    \n",
    "    precision, recall, fscore, support = score(y_test_enc, y_pred, average='macro')\n",
    "    \n",
    "    filename = to_save + \"RF\" + str(i) + '.pkl'\n",
    "    joblib.dump(rfc, filename)     \n",
    "    if gen_auc>max_auc:\n",
    "        max_auc = gen_auc\n",
    "        k_val = i\n",
    "        y_pred2 = y_pred\n",
    "        gen_auc2 = gen_auc\n",
    "        \n",
    "    print(\"METRICS:\")\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Fscore: \", fscore)\n",
    "    print(\"Gen AUC: \", gen_auc)\n",
    "    print(\"ade auc: \", ade_auc)\n",
    "    print(\"hyp auc: \", hyp_auc)\n",
    "    \n",
    "print(\"for Random forest, the best model was the trees value: \", k_val, \"with general auc: \", gen_auc2)\n",
    "print(\"confussion matrix:\")\n",
    "get_confussion_matrix(y_test_enc, y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
