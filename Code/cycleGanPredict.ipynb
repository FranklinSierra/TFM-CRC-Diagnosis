{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Useful methods**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in a directory into memory\n",
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    #enumerate filenames in directory, assume all are images\n",
    "    for filename in listdir(path):\n",
    "        # load and resize the image\n",
    "        pixels = load_img(path + filename, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, c, month, folder, label):\n",
    "    \n",
    "    pair_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/pair_images/'\n",
    "    if not os.path.exists(pair_path):\n",
    "        os.makedirs(pair_path)\n",
    "    \n",
    "    wl_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/realWL/'\n",
    "    if not os.path.exists(wl_path):\n",
    "        os.makedirs(wl_path)\n",
    "    \n",
    "    artif_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/artifNBI/'\n",
    "    if not os.path.exists(artif_path):\n",
    "        os.makedirs(artif_path)\n",
    "    \n",
    "    \n",
    "    prediction = model(test_input)\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    #saving singles images\n",
    "    \n",
    "    #real WL\n",
    "    name_file = wl_path + label + '_img_' + str(c) + '.png'\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    tf.keras.preprocessing.image.save_img(name_file, display_list[0] * 0.5 + 0.5)\n",
    "    \n",
    "    \n",
    "    #artif NBI\n",
    "    name_file = artif_path + label + '_img_' + str(c) + '.png'\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    tf.keras.preprocessing.image.save_img(name_file, display_list[1] * 0.5 + 0.5)\n",
    "\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "        \n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    name_file = pair_path + label + '_img_' + str(c) + '.png'\n",
    "    plt.savefig(name_file, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_train(image):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and reuse the Pix2Pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing optimizers, generator and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "nbi_cls_model_optimizier = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading models**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.load_model('../models/classifier/binary/MobileNet.h5', compile=True)\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = base_model.get_layer('mobilenet_1.00_224')\n",
    "x = base_model.get_layer('global_average_pooling2d')(backbone.output)\n",
    "x = base_model.get_layer('dense')(x)\n",
    "x = base_model.get_layer('dropout')(x)\n",
    "x = base_model.get_layer('dense_1')(x)\n",
    "\n",
    "nbi_cls_model = tf.keras.Model(inputs=backbone.input, outputs=x)\n",
    "print(nbi_cls_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/lossweighted/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer,\n",
    "                           nbi_cls_model=nbi_cls_model)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator_g, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **testing single video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path =  \"../../../../../data/polyp_original/WL/adenoma_WL/video_1/\"\n",
    "# load dataset white light\n",
    "# here A: white light, B: nbi light\n",
    "adenoma_WL = load_images(path)\n",
    "print(\"Adenoma WL video_1: \", adenoma_WL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adenoma_WL_array = np.asarray(adenoma_WL)\n",
    "adenoma_WL_ds = tf.data.Dataset.from_tensor_slices(adenoma_WL_array)\n",
    "adenoma_WL_ds = adenoma_WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained model on the test dataset\n",
    "for inp in adenoma_WL_ds.take(adenoma_WL.shape[0]):\n",
    "    generate_images(generator_g, inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**IGHO predicting**</font>\n",
    "\n",
    "Nota: septiembre esta en proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = \"SEPTIEMBRE\"\n",
    "txt_folder = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + 'folders.txt'\n",
    "with open(txt_folder) as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "folders = [cont.split('\\n')[0] for cont in content]\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = folders[0]\n",
    "label = 'adenoma'\n",
    "#test\n",
    "txt_path = '../imgs_results/wl2nbi/fake_images_ck4/igho/' + month + '/' + folder + '/' + 'polyps.txt'\n",
    "\n",
    "pathImgs = \"/../Datasets/Igho/Uncompressed/Videos/\"+ month + \"/\" + folder + \"/Normal/\"\n",
    "\n",
    "with open(txt_path) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "frames = [cont.split('.')[0] for cont in content]\n",
    "\n",
    "data_list = list()\n",
    "size=(256,256)\n",
    "for frame in frames:\n",
    "    to_read = pathImgs + frame + '.png'\n",
    "    pixels = load_img(to_read, target_size=size)\n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    # store\n",
    "    data_list.append(pixels)\n",
    "\n",
    "WL = asarray(data_list)\n",
    "\n",
    "print(\"The folder: {} has a shape of: {}\".format(folder,WL.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_array = np.asarray(WL)\n",
    "WL_ds = tf.data.Dataset.from_tensor_slices(WL_array)\n",
    "WL_ds = WL_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, inp in zip(frames, WL_ds.take(WL.shape[0])):\n",
    "    generate_images(generator_g, inp, index, month, folder, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting over full frames videos**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatingImages(data, generator, salve_path):\n",
    "    \n",
    "    for count, inp in enumerate(data):\n",
    "        fake = generator(inp)\n",
    "        fake = fake[0]* 0.5 + 0.5\n",
    "        #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "        fake = np.array(fake) * 255\n",
    "        fake = fake.astype(np.uint8)\n",
    "        fake_img = Image.fromarray(fake)\n",
    "        \n",
    "        #checking if directory exist\n",
    "        directory = salve_path.split('/')[:-1]\n",
    "        directory = \"/\".join(directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.mkdir(directory)\n",
    "        \n",
    "        clase = directory.split('/')[-2:]\n",
    "        clase = \"_\".join(clase)\n",
    "        salve_path = directory + '/' + clase + '_img_' + str(count) + '.png'\n",
    "        print(\"to save: \", salve_path)\n",
    "        fake_img.save(salve_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataSet(path_origen):\n",
    "    data = load_images(path_origen)\n",
    "    print(\"dimensiones de data: \", data.shape)\n",
    "    data_array = np.asarray(data)\n",
    "    data_ds = tf.data.Dataset.from_tensor_slices(data_array)\n",
    "    data_ds = data_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "                    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    \n",
    "    return data_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames from video path\n",
    "path = '/../../../Tesis/Polipos/DataSet/PolypDatasetProcesed/WL/'\n",
    "save = '/../../../maestria/propuesta/experiments/data/wl2nbi/fake_images_ck80/'\n",
    "clases = os.listdir(path)\n",
    "for clase in clases:\n",
    "    print(\"========= clase \", clase, \"=========\")\n",
    "    clase_pth = path + clase + '/'\n",
    "    videos = os.listdir(clase_pth)\n",
    "    for video in videos:\n",
    "        print(\"===\",video, \"====\")\n",
    "        video_pth = clase_pth + video + '/'\n",
    "        print(\"convirtiendo a tf.Dataset...\")\n",
    "        data_ds = toDataSet(video_pth)\n",
    "        imgs = os.listdir(video_pth)\n",
    "        print(\"prediciendo con cycleGan...\")\n",
    "        path_save = save + clase + '/' + video + '/'\n",
    "        generatingImages(data_ds, generator_g, path_save)\n",
    "            \n",
    "\n",
    "print(\"Finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting over full test frame videos**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data/binary/test_WL/'\n",
    "videos = set()\n",
    "for file in os.listdir(path):\n",
    "    clase = file.split('_')[0]\n",
    "    video = file.split('_')[-3]\n",
    "    name = clase + '_WL/video_' + video\n",
    "    videos.add(name)\n",
    "\n",
    "videos = list(videos)\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for serrated samples\n",
    "path = '../../../../../data/polyp_original/WL/serrated_WL/'\n",
    "videos = set()\n",
    "for file in os.listdir(path):\n",
    "    name = 'serrated_WL/' + file\n",
    "    videos.add(name)\n",
    "\n",
    "videos = list(videos)\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatingImages(data, generator, salve_path):\n",
    "    \n",
    "    for count, inp in enumerate(data):\n",
    "        fake = generator(inp)\n",
    "        fake = fake[0]* 0.5 + 0.5\n",
    "        #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "        fake = np.array(fake) * 255\n",
    "        fake = fake.astype(np.uint8)\n",
    "        fake_img = Image.fromarray(fake)\n",
    "        \n",
    "        #checking if directory exist\n",
    "        directory = salve_path.split('/')[:-1]\n",
    "        directory = \"/\".join(directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        clase = directory.split('/')[-2:]\n",
    "        clase = \"_\".join(clase)\n",
    "        salve_path = directory + '/' + clase + '_img_' + str(count) + '.png'\n",
    "        fake_img.save(salve_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDataSet(path_origen):\n",
    "    \n",
    "    #Make a tf dataSet for images and labels    \n",
    "    data = load_images(path_origen)\n",
    "    data_array = np.asarray(data)\n",
    "    data_ds = tf.data.Dataset.from_tensor_slices(data_array)\n",
    "    data_ds = data_ds.map(preprocess_image_test, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    return data_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../../../../../data/polyp_original/WL/'\n",
    "save = '../imgs_results/binary/lossweighted3_1_test/'\n",
    "\n",
    "for video in videos:\n",
    "    video_pth = gen_path + video + '/'\n",
    "    print(\"convirtiendo a tf.Dataset...\")\n",
    "    data_ds = toDataSet(video_pth)\n",
    "    #imgs = os.listdir(video_pth)\n",
    "    print(\"prediciendo con cycleGan...\")\n",
    "    path_save = save + video + '/'\n",
    "    generatingImages(data_ds, generator_g, path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting over external data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../../../../../../train/images/'\n",
    "save = '../imgs_results/binary/lossweighted2/linaData/train/'\n",
    "\n",
    "data_ds = toDataSet(gen_path)\n",
    "print(\"prediciendo con cycleGan...\")\n",
    "\n",
    "\n",
    "for count, inp in enumerate(data_ds):\n",
    "    fake = generator_g(inp)\n",
    "    fake = fake[0]* 0.5 + 0.5\n",
    "    #para que PIL Image deje guardar (mult por 255 and change by uint8)\n",
    "    fake = np.array(fake) * 255\n",
    "    fake = fake.astype(np.uint8)\n",
    "    fake_img = Image.fromarray(fake)\n",
    "\n",
    "    \n",
    "    salve_path = save + 'img_' + str(count) + '.png'\n",
    "    fake_img.save(salve_path)   \n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating video from fake frames predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "path = '/../../../../../../data/wl2nbi/fake_images_ck80/serrated_WL/video_2/*.png'\n",
    "\n",
    "img_array = []\n",
    "for filename in glob.glob(path):\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('serV2.avi',cv2.VideoWriter_fourcc(*'DIVX'), 7, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Predicting with netclassifier**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making csv files for white light and synthetic nbi images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path = '../../cycleGan-polyps/../../../../data/polyp_original/WL/'\n",
    "gen_path2 = '../imgs_results/binary/lossweighted/'\n",
    "\n",
    "paths = [gen_path, gen_path2]\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    if i==0:\n",
    "        csvfile = open('adeVsHypWhiteLight.csv', '+w')\n",
    "    else:\n",
    "        csvfile = open('adeVsHypArtifLossW2.csv', '+w')\n",
    "    for video in videos:\n",
    "        clase = video.split('/')[0]\n",
    "        current_class = clase.split('_')[0]\n",
    "        col_name = ','+ current_class + '\\n'\n",
    "        video_path = path + video\n",
    "        images = os.listdir(video_path)\n",
    "        for image in images:\n",
    "            img_path = video_path + '/' + image\n",
    "            csvfile.write(img_path+col_name)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../data/binary/test_NBI/'\n",
    "files = os.listdir(path)\n",
    "csvfile = open('adeVsHypNBI.csv', '+w')\n",
    "\n",
    "for file in files:\n",
    "    current_class = file.split('_')[0]\n",
    "    col_name = ',' + current_class + '\\n'\n",
    "    img_path = path + file\n",
    "    csvfile.write(img_path+col_name)\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = pd.read_csv('adeVsHypNBI.csv', header=None)\n",
    "test_df = pd.read_csv('../imgs_results/binary/lossweighted/adeVsHypArtifLossW1.csv', header=None)\n",
    "test_df.columns = ['path', 'label']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['path'].str.contains('video_11').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check: \n",
    "hyp_video1: 1988 real: 247\n",
    "hyp_video3: 1173 real: 103\n",
    "ade_video21: 1426 real: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(df_test, HEIGHT, WIDTH, tipo, batch_size):\n",
    "    \n",
    "    test_datagen=ImageDataGenerator(rescale=1/255.0)\n",
    "    \n",
    "    test_generator=test_datagen.flow_from_dataframe(directory=None,\n",
    "                                                    dataframe=df_test,\n",
    "                                                    x_col='path',\n",
    "                                                    y_col='label',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=tipo,\n",
    "                                                    target_size=(HEIGHT,WIDTH))\n",
    "\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 256, 256\n",
    "tipo = 'categorical'\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = make_generator(test_df, HEIGHT, WIDTH, tipo, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, roc_auc_score\n",
    "task = 'binary'\n",
    "\n",
    "test_gen.reset()\n",
    "logits = nbi_cls_model.predict_generator(test_gen, test_df.shape[0] // batch_size+1)\n",
    "y_pred_class = np.argmax(logits, axis=1)\n",
    "#predicted_class_probab=np.max(logits,axis=1)\n",
    "\n",
    "if task=='binary':\n",
    "    target_names = ['Adenoma', 'Hyperplastic']   \n",
    "else:\n",
    "    target_names = ['Adenoma', 'Hyperplastic', 'Serrated']    \n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_gen.classes, y_pred_class))\n",
    "print('Classification Report')\n",
    "print(classification_report(test_gen.classes, y_pred_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'binary':\n",
    "    AUC = tf.keras.metrics.AUC()\n",
    "    AUC.update_state(test_gen.classes, y_pred_class)\n",
    "    gen_auc = AUC.result()\n",
    "    print(\"AUC: \", gen_auc)\n",
    "else:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(test_gen.classes)\n",
    "    y_test_enc = le.fit_transform(test_gen.classes)\n",
    "    gen_auc = roc_auc_score(y_test_enc, logits, multi_class='ovr')\n",
    "    print(\"AUC: \", gen_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
