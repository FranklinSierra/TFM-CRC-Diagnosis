{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Libraries**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows to import generator and discriminator\n",
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import glob\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Useful methods**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image):\n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size=(256,256)):\n",
    "    data_list = list()\n",
    "    # load and resize the image\n",
    "    pixels = load_img(path, target_size=size)\n",
    "    # convert to numpy array\n",
    "    pixels = img_to_array(pixels)\n",
    "    # store\n",
    "    data_list.append(pixels)\n",
    "    return asarray(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Loading generator model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import and reuse pix2pix models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing optimizers, generators and discriminators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading generator model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../models/\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Generating fake images from full frame videos**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_path =  \"../../../../../data/polyp_original/WL/\"\n",
    "save_path = \"../imgs_results/fake_images_ck8/\"\n",
    "\n",
    "clases = os.listdir(gen_path)\n",
    "for clase in clases:\n",
    "    print(\"working on: \", clase)\n",
    "    clase_path = gen_path + clase\n",
    "    videos = os.listdir(clase_path)\n",
    "    for video in videos:\n",
    "        video_path = clase_path + '/' + video\n",
    "        images = os.listdir(video_path)\n",
    "        for image in tqdm(images):\n",
    "            img_path = video_path + '/' + image\n",
    "            img_sam = load_images(img_path)\n",
    "            img = preprocess_image_test(img_sam)\n",
    "\n",
    "            fake_sam = generator_g(img)\n",
    "            fake = fake_sam[0]*0.5 + 0.5\n",
    "            fake = resize(fake, (576, 768))         \n",
    "            to_save = save_path + clase + '/' + video + '/'\n",
    "            if not os.path.exists(to_save):\n",
    "                os.makedirs(to_save)\n",
    "            \n",
    "            filename = to_save + image\n",
    "            plt.imsave(filename, fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>**Making NBI synthetic videos**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_folder = '../imgs_results/fake_images_ck8/'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "save_path = '../fake_videos/'\n",
    "\n",
    "clases = os.listdir(general_folder)[1:]\n",
    "\n",
    "for clase in clases:\n",
    "    print(\"for clase: \", clase)\n",
    "    if clase == 'adenoma_WL':\n",
    "        cont = 0\n",
    "    elif clase == 'hiperplastic_WL':\n",
    "        cont = 40\n",
    "    else:\n",
    "        cont = 61\n",
    "    clase_path = general_folder + clase + '/'\n",
    "    videos = os.listdir(clase_path)\n",
    "    for video in videos:\n",
    "        print(video)\n",
    "        #get the video number\n",
    "        num_vid = int(video.split('_')[-1])\n",
    "        video_path = clase_path + video + '/'\n",
    "        images = os.listdir(video_path)\n",
    "        #images sorted\n",
    "        images = natsorted(images)[1:]\n",
    "        #getting space features from a frame\n",
    "        frame = cv2.imread(os.path.join(video_path, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "        \n",
    "        current_save = save_path + clase + '/' + video + '/'\n",
    "        current_number = num_vid + cont\n",
    "        video_name = current_save + \"video_\" + str(current_number) + '.mp4'        \n",
    "        \n",
    "        if not os.path.exists(current_save):\n",
    "            os.makedirs(current_save)\n",
    "        video = cv2.VideoWriter(filename=video_name, fourcc=fourcc, fps=25, frameSize=(width,height))\n",
    "        for image in tqdm(images):\n",
    "            video.write(cv2.imread(os.path.join(video_path, image)))\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "print(\"finished!\")       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
