{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce521e5",
   "metadata": {},
   "source": [
    "# <font color='red'>**Libraries**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2247c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import imageio\n",
    "from tensorflow import keras\n",
    "from skimage.transform import resize\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b418bf4",
   "metadata": {},
   "source": [
    "# <font color='red'>**Useful methods**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb55b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "    print(\"working on model: \", name)\n",
    "    \n",
    "    if name == 'vgg16':\n",
    "        path = '../models/classifier/binary/vggFinetuned/new_vgg16v4.h5'\n",
    "    else:\n",
    "        path = '../models/classifier/binary/EfficientNetV2B0/EfficientNetV2B0.h5'\n",
    "    \n",
    "    model = keras.models.load_model(path, compile=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05244fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(nom_video, test_df):\n",
    "    \n",
    "    batch = len(test_df)\n",
    "    test_datagen = ImageDataGenerator()\n",
    "    #Obtiene el n√∫mero de frames.\n",
    "    number_of_frames = test_df.Frame\n",
    "    test_generator=test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                  directory=None,\n",
    "                                                  x_col=\"path\",\n",
    "                                                  y_col=\"label\",\n",
    "                                                  batch_size=1,\n",
    "                                                  seed=42,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  target_size=(256, 256))\n",
    "    pred = model.predict_generator(test_generator, steps = batch, verbose=1)\n",
    "    for k in range(len(pred)):\n",
    "        pred_k = pred[k]\n",
    "        writer.writerow([nom_video, number_of_frames.iloc[k], pred_k[0], pred_k[1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_testing_dataframe(test_df):\n",
    "    test_df = test_df.sort_values(by='path')\n",
    "    test_df['Frame'] = (\n",
    "         test_df.apply(lambda x: int(x.path.split('/')[-1].split('_')[-1][:-4]), axis=1)\n",
    "         )\n",
    "    return test_df.sort_values(by='Frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(current_df, HEIGHT, WIDTH, batch_size):\n",
    "    \n",
    "    test_datagen = ImageDataGenerator()\n",
    "\n",
    "    test_generator=test_datagen.flow_from_dataframe(dataframe=current_df,\n",
    "                                                    x_col=\"path\",\n",
    "                                                    y_col=\"label\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=42,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    target_size=(HEIGHT, WIDTH))\n",
    "    \n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(split):\n",
    "    if split=='valid':\n",
    "        path = '../data/csv_files/adeVshyp/NBI/valNBI.csv'\n",
    "    else:\n",
    "        path = '../data/csv_files/adeVshyp/NBI/testNBI.csv'\n",
    "    \n",
    "    df = pd.read_csv(path, header=None)\n",
    "    df.columns = ['path', 'label']\n",
    "    \n",
    "    videos = []\n",
    "    for i in range(len(df)):\n",
    "        path = df.iloc[i]['path']\n",
    "        info = path.split('/')[-1]\n",
    "        clase = info.split('_')[0]\n",
    "        video = info.split('_')[3]\n",
    "        to_save = clase + '_video_' + video\n",
    "        videos.append(to_save)\n",
    "\n",
    "    videos_set = set(videos)\n",
    "    videos = list(videos_set)\n",
    "    \n",
    "    return df, videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003766b",
   "metadata": {},
   "source": [
    "# <font color='red'>**Reading and testing valid videos**</font>\n",
    "El objetivo aqui es leer el csv que contiene los frames completos de los videos de test y los serrated as additional test set. La idea es leer todo como un df y extraer iterativamente cada video de interes con el objetivo de conocer el dictamen general dado por el modelo (dado por mayoria de frames) a la hora de clasificar determinado video entre adenoma o hiperplasico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c76c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={0: 'adenoma',\n",
    "        1: 'hiperplastic'}\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc2104",
   "metadata": {},
   "source": [
    "## Knowing valid videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, val_videos = get_videos('valid')\n",
    "val_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, test_videos = get_videos('test')\n",
    "test_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique videos for valid set:\")\n",
    "print(val_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique videos for test set:\")\n",
    "print(test_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6f05f",
   "metadata": {},
   "source": [
    "## Accessing general NBI videos\n",
    "change general_data path according each case:\n",
    "* real NBI: '../../../../../data/polyp_original/NBI.csv'\n",
    "* real WL: '../../../../../data/polyp_original/WL.csv'\n",
    "* synthetic NBI: '../imgs_results/binary/embcBaseline/fold1/full_frames/embcBaselineArtifNbifold1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'vgg_baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_data = '../imgs_results/binary/embcVariation/' +experiment+'/' + experiment + 'ArtifNbi.csv'\n",
    "general_df = pd.read_csv(general_data, header=None)\n",
    "general_df.columns = ['path', 'label']\n",
    "general_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62576f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df['path'][6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff72867",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b521c",
   "metadata": {},
   "source": [
    "## <font color='red'>**Reading valid videos**</font>\n",
    "### Mayoring voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['vgg_baseline', 'Mobilenet']\n",
    "print(\"model loading... \")\n",
    "model = load_model('vgg16')\n",
    "\n",
    "for experiment in experiments:\n",
    "    print(\"=========== WORKING ON: \", experiment, \" ===========\")\n",
    "    save_path = '../imgs_results/binary/embcVariation/' + experiment + '/'\n",
    "    \n",
    "    print(\"===== reading dataframe \", experiment)\n",
    "    #general_data = '../imgs_results/binary/embcVariation/test/'+experiment+'/'+experiment+'ArtifNbi.csv'\n",
    "    \n",
    "    general_df = pd.read_csv(general_data, header=None)\n",
    "    general_df.columns = ['path', 'label']\n",
    "    print(\"dataframe readed!\")\n",
    "    \n",
    "    to_save = save_path + experiment + 'ArtifNbiPreds.txt'\n",
    "    with open(to_save, 'w') as f:\n",
    "        for video in test_videos:\n",
    "            clase = video.split('_')[0]\n",
    "            num_vid = video.split('_')[-1]\n",
    "            print(\"==== working on class: \", clase, \" video: \", num_vid, \" ====\")\n",
    "            to_write = \"==== WORKING ON: \" +str(clase)+\" video: \"+str(num_vid)+\" ====\"\n",
    "            f.write(to_write)\n",
    "            f.write('\\n')\n",
    "\n",
    "            #searching for current valid video\n",
    "            ade_probs, hyp_probs = [], []\n",
    "            key = clase + '_WL/video_' + num_vid + '/'\n",
    "            current_df = general_df[general_df['path'].str.contains(key)]        \n",
    "            test_gen = make_generator(current_df, HEIGHT, WIDTH, batch_size)\n",
    "            probs = model.predict(test_gen)\n",
    "            for prob in probs:\n",
    "                label = labels[np.argmax(prob)]\n",
    "                if label == \"adenoma\":\n",
    "                    value = round(np.max(prob), 2)\n",
    "                    ade_probs.append(value)\n",
    "                else:\n",
    "                    value = round(np.max(prob), 2)\n",
    "                    hyp_probs.append(value)\n",
    "\n",
    "            if len(ade_probs) > len(hyp_probs):\n",
    "                final_decision = \"ADENOMA \"\n",
    "            else:\n",
    "                final_decision = \"HYPERPLASTIC \"\n",
    "\n",
    "            print(\"total frames: \"+ str(len(current_df)) + \" votes for adenoma: {} for hyperp: {}\".\n",
    "                  format(len(ade_probs), len(hyp_probs)))\n",
    "\n",
    "            to_write = (\"video: \"+str(num_vid)+\" total frames: \"+str(len(current_df))+\n",
    "            \" votes for adenoma: \"+str(len(ade_probs))+\" votes for hyper: \"+str(len(hyp_probs))+\n",
    "            \" final decision: \" + final_decision)\n",
    "            f.write(to_write)\n",
    "            ade_probs = np.array(ade_probs)\n",
    "            ade_mean = round(ade_probs.mean(),2)\n",
    "            hyp_probs = np.array(hyp_probs)\n",
    "            hyp_mean = round(hyp_probs.mean(),2)\n",
    "            print(\"ade mean: {}, hyp mean: {}\".format(ade_mean, hyp_mean))\n",
    "            to_write = \"adenoma mean: \" + str(ade_mean) + \" hyper mean: \" + str(hyp_mean) + \"\\n\"\n",
    "            f.write(to_write)\n",
    "    f.close()\n",
    "    print(\"finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bddf51",
   "metadata": {},
   "source": [
    "## <font color='red'>**General metrics**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e30f6c",
   "metadata": {},
   "source": [
    "### Frames decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = sorted(test_videos)\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = 'adenoma_WL/video_10'\n",
    "tmp_df = general_df[general_df['path'].str.contains(to_check)]\n",
    "\n",
    "for video in videos[1:]:\n",
    "    clase = video.split('_')[0]\n",
    "    num_vid = video.split('_')[-1]\n",
    "    to_check = clase + '_WL/video_' + num_vid + '/'\n",
    "    current_df = general_df[general_df['path'].str.contains(to_check)]\n",
    "    tmp_df = pd.concat([tmp_df, current_df], axis=0)\n",
    "\n",
    "\n",
    "tmp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first record: \\n\")\n",
    "print(tmp_df.iloc[0]['path'])\n",
    "print(\"last record: \\n\")\n",
    "print(tmp_df.iloc[-1]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff196a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "test_gen = make_generator(tmp_df, HEIGHT, WIDTH, batch_size)\n",
    "test_gen.reset()\n",
    "logits = model.predict(test_gen, tmp_df.shape[0] // batch_size+1)\n",
    "y_pred_class = np.argmax(logits, axis=1)\n",
    "\n",
    "target_names = ['Adenoma', 'Hyperplastic']      \n",
    "\n",
    "print('Confusion Matrix for experiment: ')#, experiment)\n",
    "print(confusion_matrix(test_gen.classes, y_pred_class))\n",
    "print('Classification Report')\n",
    "print(classification_report(test_gen.classes, y_pred_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "target_names = ['adenoma', 'hyperplastic']\n",
    "cm = confusion_matrix(test_gen.classes, y_pred_class, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp = disp.plot(include_values=True, cmap=plt.cm.Blues, xticks_rotation='horizontal', values_format='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24236a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = tf.keras.metrics.AUC()\n",
    "AUC.update_state(test_gen.classes, y_pred_class)\n",
    "AUC.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a720f5",
   "metadata": {},
   "source": [
    "### Online prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model loading... \")\n",
    "model = load_model('vgg16')\n",
    "\n",
    "save_path = '../imgs_results/binary/embcVariation/vgg_baseline/'\n",
    "to_write = save_path + 'onlinePreds.csv'\n",
    "\n",
    "print(\"===== leyendo dataframe para \", experiment)\n",
    "general_df = pd.read_csv(general_data, header=None)\n",
    "general_df.columns = ['path', 'label']\n",
    "print(\"dataframe leido!\")\n",
    "\n",
    "with open( to_write, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    for video in videos:\n",
    "        clase = video.split('_')[0]\n",
    "        num_vid = video.split('_')[-1]\n",
    "        to_check = clase + '_WL_video_' + str(num_vid) + '_img'\n",
    "        single_df = general_df[general_df['path'].str.contains(to_check)]\n",
    "        print(\"length of single_df: \", len(single_df))\n",
    "        single_df = sort_testing_dataframe(single_df)\n",
    "        nom_video = to_check\n",
    "        predict(nom_video, clase, model, single_df)\n",
    "    \n",
    "    #for serrated samples\n",
    "    for i in range(15):\n",
    "        to_check = 'serrated_WL_video_' + str(i+1) + '_img'\n",
    "        single_df = general_df[general_df['path'].str.contains(to_check)]\n",
    "        print(\"length of single_df: \", len(single_df))\n",
    "        single_df = sort_testing_dataframe(single_df)\n",
    "        nom_video = to_check\n",
    "        predict(nom_video, clase, model, single_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
